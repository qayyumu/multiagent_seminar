{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crewai crewai_tools langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "choose_LLM = 1\n",
    "colab_exp = 0\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "if choose_LLM==1:\n",
    "    if(colab_exp):\n",
    "        from google.colab import userdata    ###for colab use\n",
    "        llm = ChatOpenAI(model = \"gpt-4o-mini\",openai_api_key=userdata.get('OPENAI_API_KEY'))\n",
    "    else:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv() \n",
    "        llm = \"gpt-4o-mini\" #ChatOpenAI(model = \"gpt-4o-mini\",openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "else:\n",
    "    llm = ChatOpenAI(model=\"ollama/llama3.2\", base_url=\"http://localhost:11434\",temperature=0.1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
    "\n",
    "# from google.colab import userdata    ###for colab use\n",
    "# serper_key = userdata.get('SERPER_key')\n",
    "\n",
    "serper_key = os.getenv(\"SERPER_API_KEY\")\n",
    "os.environ[\"SERPER_API_KEY\"] = serper_key\n",
    "\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_agent = Agent(\n",
    "    role=\"Data Analyst\",\n",
    "    goal=\"Monitor and analyze market data in real-time \"\n",
    "         \"to identify trends and predict market movements.\",\n",
    "    backstory=\"Specializing in financial markets, this agent \"\n",
    "              \"uses statistical modeling and machine learning \"\n",
    "              \"to provide crucial insights. With a knack for data, \"\n",
    "              \"the Data Analyst Agent is the cornerstone for \"\n",
    "              \"informing trading decisions.\",\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    "    tools = [scrape_tool, search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_strategy_agent = Agent(\n",
    "    role=\"Trading Strategy Developer\",\n",
    "    goal=\"Develop and test various trading strategies based \"\n",
    "         \"on insights from the Data Analyst Agent.\",\n",
    "    backstory=\"Equipped with a deep understanding of financial \"\n",
    "              \"markets and quantitative analysis, this agent \"\n",
    "              \"devises and refines trading strategies. It evaluates \"\n",
    "              \"the performance of different approaches to determine \"\n",
    "              \"the most profitable and risk-averse options.\",\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    "    tools = [scrape_tool, search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Data Analyst Agent: Analyze Market Data\n",
    "data_analysis_task = Task(\n",
    "    description=(\n",
    "        \"Continuously monitor and analyze market data for \"\n",
    "        \"the selected stock ({stock_selection}). \"\n",
    "        \"Use statistical modeling and machine learning to \"\n",
    "        \"identify trends and predict market movements.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"Insights and alerts about significant market \"\n",
    "        \"opportunities or threats for {stock_selection}.\"\n",
    "    ),\n",
    "    agent=data_analyst_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Trading Strategy Agent: Develop Trading Strategies\n",
    "strategy_development_task = Task(\n",
    "    description=(\n",
    "        \"Develop and refine trading strategies based on \"\n",
    "        \"the insights from the Data Analyst and \"\n",
    "        \"user-defined risk tolerance ({risk_tolerance}). \"\n",
    "        \"Consider trading preferences ({trading_strategy_preference}).\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A set of potential trading strategies for {stock_selection} \"\n",
    "        \"that align with the user's risk tolerance.\"\n",
    "    ),\n",
    "    agent=trading_strategy_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define the crew with agents and tasks\n",
    "financial_trading_crew = Crew(\n",
    "    agents=[data_analyst_agent, \n",
    "            trading_strategy_agent ],\n",
    "    \n",
    "    tasks=[data_analysis_task, \n",
    "           strategy_development_task ],\n",
    "    \n",
    "    manager_llm=llm,\n",
    "    process=Process.hierarchical,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data for kicking off the process\n",
    "financial_trading_inputs = {\n",
    "    'stock_selection': 'NVDA',\n",
    "    'risk_tolerance': 'Medium',\n",
    "    'trading_strategy_preference': 'Day Trading',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 22:23:33,856 - 8783415296 - llm.py-llm:170 - ERROR: LiteLLM call failed: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-rZOR5A4vLgEAZGYa0OLQQdl3 on tokens per min (TPM): Limit 200000, Requested 403945. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 22:26:20,157 - 8783415296 - llm.py-llm:170 - ERROR: LiteLLM call failed: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-rZOR5A4vLgEAZGYa0OLQQdl3 on tokens per min (TPM): Limit 200000, Requested 403516. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 22:26:46,437 - 8783415296 - llm.py-llm:170 - ERROR: LiteLLM call failed: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-rZOR5A4vLgEAZGYa0OLQQdl3 on tokens per min (TPM): Limit 200000, Requested 403787. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 22:27:13,565 - 8783415296 - llm.py-llm:170 - ERROR: LiteLLM call failed: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-rZOR5A4vLgEAZGYa0OLQQdl3 on tokens per min (TPM): Limit 200000, Requested 403739. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTrading Strategy Developer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mCan you please explain your approach to using ARIMA and GARCH models for the analysis of NVDA stock data? Specifically, what key indicators do you typically look for that might signal market movements, and how do you backtest your models to ensure their reliability?\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTrading Strategy Developer\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to gather information about using ARIMA and GARCH models for analyzing stock data, particularly for NVDA stock. This will help me provide a detailed response that aligns with the context shared.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"search_query\\\": \\\"ARIMA GARCH models analysis NVDA stock key indicators backtesting\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "Search results: Title: [PDF] Predicting NVIDIA's Next-Day Stock Price: A Comparative Analysis ...\n",
      "Link: https://arxiv.org/pdf/2405.08284?\n",
      "Snippet: Our study analyzes four key models: ARIMA, LSTM, MLP, and ARIMA-. GARCH, each selected for its significance and capability in accurately forecasting NVIDIA's ...\n",
      "---\n",
      "Title: Forecasting NVIDIA's Stock with AI: A Study of Predictive Models\n",
      "Link: https://onepagecode.substack.com/p/forecasting-nvidias-stock-with-ai\n",
      "Snippet: For predicting the stock price, the ARIMA-GARCH model has the lowest RSME. The findings suggest that volatility modeling is more accurate when ...\n",
      "---\n",
      "Title: (PDF) Predicting stock market indicators using a hybrid model (ARIMA\n",
      "Link: https://www.researchgate.net/publication/394214203_Predicting_stock_market_indicators_using_a_hybrid_model_ARIMA_-_GARCH_An_analytical_study_of_some_Gulf_financial_market_indicators\n",
      "Snippet: Purpose: The research aims to compare the results of forecasting financial market indicators in the Arabian Gulf using the hybrid ARIMA-GARCH ...\n",
      "---\n",
      "Title: ARIMA Analysis of Stock Returns - EODHD APIs - Medium\n",
      "Link: https://eodhd.medium.com/arima-analysis-of-stock-returns-66f0ea6b1ca8\n",
      "Snippet: ARIMA, the Autoregressive Integrated Moving Average model, as a powerful statistical tool. It helps uncover and predict subtle trends in financial time series.\n",
      "---\n",
      "Title: [Literature Review] Predicting NVIDIA's Next-Day Stock Price\n",
      "Link: https://www.themoonlight.io/en/review/predicting-nvidias-next-day-stock-price-a-comparative-analysis-of-lstm-mlp-arima-and-arima-garch-models\n",
      "Snippet: ARIMA-GARCH: A hybrid model combining ARIMA with GARCH (Generalized Autoregressive Conditional Heteroskedasticity) to model both the mean and volatility ( ...\n",
      "---\n",
      "Title: [PDF] Stock Forecasting and Portfolio Optimization Based on ARIMA ...\n",
      "Link: https://www.atlantis-press.com/article/126008567.pdf\n",
      "Snippet: The. ARIMA-GARCH model is tested by using the residuals from the ARIMA model as parameters for the GARCH model to complete the fitting. The ...\n",
      "---\n",
      "Title: GARCH Analysis on Volatility Patterns | EODHD APIs Academy\n",
      "Link: https://eodhd.com/financial-academy/stocks-data-analysis-examples/garch-analysis-on-volatility-patterns\n",
      "Snippet: This article provides the information needed to apply the Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model for analyzing and modeling ...\n",
      "---\n",
      "Title: Pocket Option's Ultimate learn to NVDA Stock Price Prediction 2025\n",
      "Link: https://pocketoption.com/blog/en/knowledge-base/markets/nvda-stock-price-prediction-2025/\n",
      "Snippet: Our comprehensive analysis suggests a base case price target range of $280-$340 for NVIDIA shares by 2025, with significant upside potential.\n",
      "---\n",
      "Title: NVIDIA Stock Analysis - GitHub\n",
      "Link: https://github.com/debjit-mandal/NVIDIA-Stock-Analysis\n",
      "Snippet: Includes EDA, time series forecasting (ARIMA, LSTM), and volatility analysis (GARCH) to uncover trends and insights for market analysis and trading strategies.\n",
      "---\n",
      "Title: [PDF] Nvidia's stock returns prediction using machine learning techniques ...\n",
      "Link: https://www.econstor.eu/bitstream/10419/324538/1/1786412241.pdf\n",
      "Snippet: As mentioned above, the models used in this article are based on variables from various sources namely fundamental analysis of Nvidia Corporation, technical.\n",
      "---\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTrading Strategy Developer\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI found several sources discussing the application of ARIMA and GARCH models, particularly in analyzing NVIDIA's stock. I will compile the relevant information to explain my approach, key indicators, and backtesting methods.\n",
      "Thought: I will select the most relevant articles that discuss ARIMA and GARCH models in the context of NVDA stock data for further insights.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead website content\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"website_url\\\": \\\"https://www.themoonlight.io/en/review/predicting-nvidias-next-day-stock-price-a-comparative-analysis-of-lstm-mlp-arima-and-arima-garch-models\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "[Literature Review] Predicting NVIDIA's Next-Day Stock Price: A Comparative Analysis of\n",
      " LSTM, MLP, ARIMA, and ARIMA-GARCH Models open navigation menu FeaturesPricingFAQBlogopen navigation menu FeaturesPricingFAQBlogENUpload PaperDownload Chrome ExtensionThis page provides the most accurate and concise summary worldwide for the paper titled Predicting NVIDIA's Next-Day Stock Price: A Comparative Analysis of\n",
      " LSTM, MLP, ARIMA, and ARIMA-GARCH Models. With Moonlight, your AI research colleague, you can effortlessly and quickly grasp all the papers you read. Install the Chrome extension from https://www.themoonlight.io/ or directly upload files on the web. Moonlight offers features tailored to your needs: - Text Explanation: AI simplifies complex concepts and paragraphs. - Image Explanation: One-click explanations of images, tables, and formulas. - AI Chat: Engage with AI to dive deeper into paper discussions. - Smart Citations: Instantly view information (title, author, summary) of cited papers without scrolling to the References. - Translation: Quickly translate unfamiliar words, sentences, or the entire page. - Auto Highlight: AI highlights key points automatically, helping you identify originality, methods, and results swiftly. - External Link Explanation: AI analyzes external sources and explains their relevance to your document. - Markup: Highlight important sentences and annotate to create personalized research notes. - Save and Share: Store documents in your library and easily share them. - Scholar Deep Search: Receive recommendations of relevant papers based on your stored documents.[Literature Review] Predicting NVIDIA's Next-Day Stock Price: A Comparative Analysis of\n",
      " LSTM, MLP, ARIMA, and ARIMA-GARCH Models Open PDF directly 2024-05-14https://arxiv.org/pdf/2405.08284KeywordsStock predictionNVIDIAARIMAMLPLSTMARIMA-GARCHThis review was written by AI. Install the Moonlight extension to get free AI summaries every time you open a PDF.Okay, let's break down this paper in detail.\n",
      "Overall Goal and Context:\n",
      "The paper aims to predict the next-day stock price of NVIDIA (NVDA) using and comparing several time series models. Predicting stock prices is a notoriously difficult problem in finance, but important for investors. The authors specifically focus on NVIDIA because of its significant role in the ongoing AI boom, making its stock performance particularly interesting. The core idea is to see which model performs best in this specific context.\n",
      "Models Compared:\n",
      "The paper evaluates four different models:\n",
      "ARIMA (Autoregressive Integrated Moving Average): A classical time series model that captures linear dependencies in data.\n",
      "MLP (Multilayer Perceptron): A basic type of feedforward neural network, capable of modeling non-linear relationships.\n",
      "LSTM (Long Short-Term Memory): A type of recurrent neural network (RNN) designed to handle sequential data with long-term dependencies, often used in time series forecasting.\n",
      "ARIMA-GARCH: A hybrid model combining ARIMA with GARCH (Generalized Autoregressive Conditional Heteroskedasticity) to model both the mean and volatility (variance) of the stock price.\n",
      "Data:\n",
      "The data used is the daily adjusted closing price of NVIDIA stock from April 12, 2019, to April 11, 2024, obtained from the Yahoo Finance API. This constitutes a time series of 1258 data points. The data is split into training (90%) and testing (10%) sets.\n",
      "Core Methodology (Detailed and Technical):\n",
      "Let's dive into each model's methodology in detail:\n",
      "1. ARIMA\n",
      "Core Idea: ARIMA models the current value of a time series as a function of its past values (autoregressive component), past errors (moving average component), and the degree of differencing needed to make the series stationary (integrated component).\n",
      "Stationarity: Financial time series are often non-stationary (meaning their statistical properties change over time). The first step is to make the series stationary by differencing. Differencing involves subtracting the previous value from the current value: new_value(t) = value(t) - value(t-1). The \"I\" in ARIMA refers to the order of differencing required.\n",
      "AR Component (AR(p)): This component models the current value as a linear combination of its p previous values. Mathematically:\n",
      "X(t) = phi_1 * X(t-1) + phi_2 * X(t-2) + ... + phi_p * X(t-p) + error(t)\n",
      "where X(t) is the value at time t, phi_i are the model parameters (coefficients), and error(t) is the error term (white noise).\n",
      "MA Component (MA(q)): This component models the current value as a linear combination of the q previous error terms (residuals). Mathematically:\n",
      "X(t) = error(t) + theta_1 * error(t-1) + theta_2 * error(t-2) + ... + theta_q * error(t-q)\n",
      "where theta_i are the model parameters.\n",
      "Model Order (p, d, q): ARIMA models are denoted as ARIMA(p, d, q), where:\n",
      "p is the order of the autoregressive (AR) component.\n",
      "d is the order of differencing (I).\n",
      "q is the order of the moving average (MA) component.\n",
      "Parameter Estimation: The key is to determine the optimal values for p, d, and q, and the coefficients phi_i and theta_i. This is typically done using statistical methods like minimizing the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC) on the training data. These criteria balance model fit with model complexity (to avoid overfitting). The paper uses AIC.\n",
      "Expanding vs. Rolling Window: The authors explore two approaches for using historical data:\n",
      "Expanding Window: Start with a small amount of training data and fit the ARIMA model. As you predict further into the test set, add the actual values from the test set to the training data and re-fit the model. The training window grows over time.\n",
      "Rolling Window: Use a fixed-size window of the most recent data to train the model. As you predict further, shift the window forward, discarding the oldest data and including the newest data.\n",
      "Implementation Details: The paper first performs the Augmented Dickey-Fuller (ADF) test to confirm the non-stationarity of the raw data. After differencing, the ADF test is used to confirm stationarity. Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots are used to get initial estimates for p and q. The \"optimal\" p and q are found by iterating over a range of values (0 to 4) and selecting the parameters with the lowest AIC.\n",
      "2. MLP\n",
      "Core Idea: MLP is a feedforward neural network that learns non-linear mappings between inputs and outputs. It consists of multiple layers of interconnected nodes (\"neurons\").\n",
      "Architecture: The basic architecture is:\n",
      "Input Layer: Receives the input data (e.g., past stock prices).\n",
      "Hidden Layers: One or more layers of neurons that perform non-linear transformations of the input data. Each neuron applies a weighted sum of its inputs, followed by an activation function.\n",
      "Output Layer: Produces the final prediction (e.g., the next-day stock price).\n",
      "Activation Functions: Non-linear functions applied to the output of each neuron. Common choices include ReLU (Rectified Linear Unit), sigmoid, or tanh. The paper uses ReLU.\n",
      "Training: MLPs are trained using backpropagation and gradient descent. The goal is to minimize a loss function (e.g., Mean Squared Error) by adjusting the weights and biases of the network.\n",
      "Hyperparameter Tuning: The performance of an MLP depends heavily on its hyperparameters (e.g., the number of layers, the number of neurons per layer, the learning rate, the batch size, the number of epochs). These parameters are typically tuned using a validation set.\n",
      "Implementation Details: The authors normalize the time series data using a MinMaxScaler. They split the data into 80% training, 10% validation, and 10% testing. Hyperparameters (number of layers, neurons per layer, activation function, look-back period, learning rate, batch size, epochs) are determined through \"trial-and-error\" by observing the model's performance on the validation set.\n",
      "Look-Back Window: The MLP uses a \"look-back\" window to create input features. For example, if the look-back is 3 days, the input to the MLP would be the stock prices for the past 3 days, and the output would be the predicted price for the next day.\n",
      "3. LSTM\n",
      "Core Idea: LSTMs are a special type of RNN designed to overcome the vanishing gradient problem that can occur when training standard RNNs on long sequences. LSTMs have \"memory cells\" that can store information over long periods.\n",
      "Recurrent Neural Network (RNN): RNN processes sequential data by maintaining a \"hidden state\" that is updated at each time step based on the current input and the previous hidden state. This allows the network to \"remember\" information from earlier time steps. However, standard RNNs struggle with long-term dependencies because the gradients used to train the network can vanish or explode as they are backpropagated through time.\n",
      "LSTM Architecture: LSTMs address the vanishing gradient problem by introducing a more complex cell structure with \"gates\" that control the flow of information into and out of the cell.\n",
      "Cell State: The core of the LSTM, which carries information across time steps.\n",
      "Forget Gate: Determines which information to discard from the cell state.\n",
      "Input Gate: Determines which new information to add to the cell state.\n",
      "Output Gate: Determines what information to output from the cell state.\n",
      "Equations: The equations in the paper describe the mathematical operations performed by these gates (see the original response to see these equations).\n",
      "Training: LSTMs are trained using backpropagation through time (BPTT).\n",
      "Hyperparameter Tuning: Similar to MLPs, LSTMs have many hyperparameters that need to be tuned, including the number of layers, the number of neurons per layer, the learning rate, the batch size, the sequence length (look-back period), and the type of activation function.\n",
      "Implementation Details: Similar to the MLP model, the authors use the MinMaxScaler for data normalization and split the data into training, validation, and testing sets. The LSTM model is also trained using \"trial and error\" to identify the optimal configuration.\n",
      "4. ARIMA-GARCH\n",
      "Core Idea: This is a hybrid model that combines the strengths of ARIMA and GARCH. ARIMA models the mean of the time series, while GARCH models the volatility (variance) of the time series. Financial time series often exhibit volatility clustering, meaning that periods of high volatility tend to be followed by more periods of high volatility, and vice versa. GARCH models are designed to capture this behavior.\n",
      "GARCH Component (GARCH(m, r)): GARCH models the conditional variance (volatility) as a function of past squared errors and past conditional variances.\n",
      "sigma(t)^2 = omega + sum(gamma_i * epsilon(t-i)^2) + sum(beta_j * sigma(t-j)^2)\n",
      "where sigma(t)^2 is the conditional variance at time t, omega, gamma_i, and beta_j are model parameters, epsilon(t-i) are the past errors (residuals), and sigma(t-j)^2 are the past conditional variances. The parameters m and r define the order of the GARCH model (how many past squared errors and past variances to include).\n",
      "Combining ARIMA and GARCH: The general process is:\n",
      "Fit an ARIMA model to the time series data.\n",
      "Extract the residuals (errors) from the ARIMA model.\n",
      "Fit a GARCH model to the residuals. This captures the volatility dynamics that the ARIMA model couldn't explain.\n",
      "Use the GARCH model to forecast future volatility.\n",
      "Use the ARIMA model, along with the forecasted volatility from the GARCH model, to make final predictions.\n",
      "Implementation Details: The authors integrate a GARCH(1,1) model with the best-performing ARIMA model. They justify the use of GARCH(1,1) because it requires fewer parameters to estimate and is a common choice in the literature for stock price prediction. They don't provide details on how the forecasted volatility from GARCH is integrated with the ARIMA forecast to produce the final stock price prediction.\n",
      "Evaluation Metrics:\n",
      "The models are evaluated using three metrics:\n",
      "MAE (Mean Absolute Error): The average absolute difference between the predicted and actual values.\n",
      "RMSE (Root Mean Squared Error): The square root of the average squared difference between predicted and actual values. RMSE penalizes large errors more heavily than MAE.\n",
      "R-squared (R2): The coefficient of determination, which represents the proportion of variance in the dependent variable that is explained by the model. Ranges from 0 to 1, with higher values indicating a better fit.\n",
      "Results and Conclusion:\n",
      "The results show that:\n",
      "The ARIMA model with an expanding window slightly outperforms the ARIMA models with rolling windows.\n",
      "The ARIMA-GARCH model achieves the lowest RMSE and the highest R-squared, suggesting superior predictive accuracy and variance explanation. However, it also has the highest MAE, indicating that it tends to overpredict values towards the end of the testing set.\n",
      "The ARIMA model with an expanding window outperforms the LSTM and MLP models.\n",
      "The authors conclude that, in this particular case, the simpler ARIMA model is effective because the stock price series may not exhibit strong non-linear patterns. They also suggest that the LSTM and MLP models might not have been optimally tuned, which could have hindered their performance.\n",
      "Possible Improvements and Future Research:\n",
      "The authors suggest several avenues for future research:\n",
      "Extend the prediction horizon beyond the next day.\n",
      "Incorporate a larger dataset to improve the training of the LSTM and MLP models.\n",
      "Explore other feature engineering techniques to improve the performance of the models.\n",
      "Investigate why the ARIMA-GARCH model overpredicts.\n",
      "In summary, this paper provides a comparative analysis of different time series models for predicting NVIDIA's stock price. While the hybrid ARIMA-GARCH model shows promise, the simpler ARIMA model performs\n",
      " Read smarter, not harder â€“ powered by Moonlight Read with MoonlightSimilar Reviews [Literature Review] Comparative Analysis of LSTM, GRU, and Transformer Models for Stock\n",
      " Price Prediction [Literature Review] Forecasting S&P 500 Using LSTM Models [Literature Review] Analysis and Predictive Modeling of Solar Coronal Holes Using Computer\n",
      " Vision and ARIMA-LSTM Networks [Literature Review] Predicting Stock Prices with FinBERT-LSTM: Integrating News Sentiment\n",
      " Analysis [Literature Review] Enhancing Time Series Forecasting via a Parallel Hybridization of ARIMA\n",
      " and Polynomial ClassifiersUpload your paper and start for free Select FileOr Drop PDF file here. UploadUpload Terms of UsePrivacy PolicyMediumGitHubLinkedInEmailCorca, Inc. / CEO Younghyun Chung / Business Registration Number 271-86-0220634, Yeongdong-daero 85-gil, Gangnam-gu, Seoul, Republic of Korea, 06180Contact 02-6925-6978 E-mail: moonlight@corca.aiÂ© 2025 Corca, Inc. All rights reserved.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTrading Strategy Developer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "In analyzing NVDA stock data using ARIMA and GARCH models, my approach encompasses several key methodologies and indicators, ensuring a robust framework for forecasting and risk management.\n",
      "\n",
      "**ARIMA Model (Autoregressive Integrated Moving Average):**\n",
      "1. **Purpose**: ARIMA helps in predicting stock prices by modeling the mean of the time series, relying heavily on past values and errors.\n",
      "2. **Key Indicators**:\n",
      "   - **Stationarity**: Financial time series often exhibit non-stationarity. The Augmented Dickey-Fuller (ADF) test is used to determine this.\n",
      "   - **Parameter Selection**: The model is represented as ARIMA(p, d, q); the parameters p (autoregressive), d (differencing), and q (moving average) must be optimized, typically through criteria like AIC (Akaike Information Criterion).\n",
      "   - **Autocorrelation**: The Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots are employed to identify potential values for p and q.\n",
      "\n",
      "**GARCH Model (Generalized Autoregressive Conditional Heteroskedasticity)**:\n",
      "1. **Purpose**: GARCH models the volatility of stock prices, where periods of high volatility tend to cluster together. This model can elucidate the variance dynamics that classic ARIMA might miss.\n",
      "2. **Key Indicators**:\n",
      "   - **Conditional Variance**: GARCH models incorporate past squared residuals and conditional variances to capture changing volatility over time.\n",
      "   - **Integration with ARIMA**: We fit an ARIMA model to the price data first and then use the residuals to inform the GARCH model for forecasting volatility, highlighting potential risk levels.\n",
      "\n",
      "**Backtesting the Models**:\n",
      "1. **Training and Testing Sets**: The NVDA dataset used spans daily adjusted closing prices over a specified period, generally split into training (90%) and testing sets (10%).\n",
      "2. **Rollings and Expanding Windows**: Two methodologies are used during backtesting:\n",
      "   - **Expanding Window**: This lets the training dataset grow as new data points come in, continuously refining the model with recent information.\n",
      "   - **Rolling Window**: Alternatively, this approach keeps a fixed-size window, which is shifted over time to incorporate the latest data while discarding older data.\n",
      "3. **Performance Metrics**: The models are evaluated using metrics like:\n",
      "   - **MAE (Mean Absolute Error)**: Measures average absolute differences between predictions and actual values.\n",
      "   - **RMSE (Root Mean Squared Error)**: Penalizes larger prediction errors more heavily, offering insights into model accuracy.\n",
      "   - **R-squared**: Indicates the proportion of variance in the stock prices explained by the model, with higher values suggesting better fit.\n",
      "\n",
      "In summary, by leveraging ARIMA for mean modeling and GARCH for volatility analysis, we effectively predict NVDA stock movements while incorporating risk management through our backtesting procedures. This methodology aligns with a risk-averse trading strategy that accommodates user-defined risk tolerance levels, thereby enhancing our decision-making process in the trading arena.\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I will take a different approach and formulate a question for the Trading Strategy Developer to gather specific insights related to their assessment of the NVDA stock analysis task. This may help me to further inform how to proceed with the delegation or even contribute to the final strategy.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mAsk question to coworker\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"question\\\": \\\"Can you please explain your approach to using ARIMA and GARCH models for the analysis of NVDA stock data? Specifically, what key indicators do you typically look for that might signal market movements, and how do you backtest your models to ensure their reliability?\\\", \\\"context\\\": \\\"Understanding your approach will assist in refining the trading strategies based on quantitative analysis. The goal is to align your insights with user-defined risk tolerance levels and the preferences for day trading strategies. Your analysis will also influence how we manage potential risks and identify opportunities.\\\", \\\"coworker\\\": \\\"Trading Strategy Developer\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "In analyzing NVDA stock data using ARIMA and GARCH models, my approach encompasses several key methodologies and indicators, ensuring a robust framework for forecasting and risk management.\n",
      "\n",
      "**ARIMA Model (Autoregressive Integrated Moving Average):**\n",
      "1. **Purpose**: ARIMA helps in predicting stock prices by modeling the mean of the time series, relying heavily on past values and errors.\n",
      "2. **Key Indicators**:\n",
      "   - **Stationarity**: Financial time series often exhibit non-stationarity. The Augmented Dickey-Fuller (ADF) test is used to determine this.\n",
      "   - **Parameter Selection**: The model is represented as ARIMA(p, d, q); the parameters p (autoregressive), d (differencing), and q (moving average) must be optimized, typically through criteria like AIC (Akaike Information Criterion).\n",
      "   - **Autocorrelation**: The Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots are employed to identify potential values for p and q.\n",
      "\n",
      "**GARCH Model (Generalized Autoregressive Conditional Heteroskedasticity)**:\n",
      "1. **Purpose**: GARCH models the volatility of stock prices, where periods of high volatility tend to cluster together. This model can elucidate the variance dynamics that classic ARIMA might miss.\n",
      "2. **Key Indicators**:\n",
      "   - **Conditional Variance**: GARCH models incorporate past squared residuals and conditional variances to capture changing volatility over time.\n",
      "   - **Integration with ARIMA**: We fit an ARIMA model to the price data first and then use the residuals to inform the GARCH model for forecasting volatility, highlighting potential risk levels.\n",
      "\n",
      "**Backtesting the Models**:\n",
      "1. **Training and Testing Sets**: The NVDA dataset used spans daily adjusted closing prices over a specified period, generally split into training (90%) and testing sets (10%).\n",
      "2. **Rollings and Expanding Windows**: Two methodologies are used during backtesting:\n",
      "   - **Expanding Window**: This lets the training dataset grow as new data points come in, continuously refining the model with recent information.\n",
      "   - **Rolling Window**: Alternatively, this approach keeps a fixed-size window, which is shifted over time to incorporate the latest data while discarding older data.\n",
      "3. **Performance Metrics**: The models are evaluated using metrics like:\n",
      "   - **MAE (Mean Absolute Error)**: Measures average absolute differences between predictions and actual values.\n",
      "   - **RMSE (Root Mean Squared Error)**: Penalizes larger prediction errors more heavily, offering insights into model accuracy.\n",
      "   - **R-squared**: Indicates the proportion of variance in the stock prices explained by the model, with higher values suggesting better fit.\n",
      "\n",
      "In summary, by leveraging ARIMA for mean modeling and GARCH for volatility analysis, we effectively predict NVDA stock movements while incorporating risk management through our backtesting procedures. This methodology aligns with a risk-averse trading strategy that accommodates user-defined risk tolerance levels, thereby enhancing our decision-making process in the trading arena.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "**Potential Trading Strategies for NVDA Aligned with Medium Risk Tolerance:**\n",
      "\n",
      "1. **Momentum Trading Strategy**:\n",
      "   - **Use Case**: Designed for short-term trading (day trading) based on the momentum of stock price movements.\n",
      "   - **Indicators**: \n",
      "     - Utilize ARIMA for time series forecasting to identify upward momentum in NVDA stock prices.\n",
      "     - Implementation of buy signals when the price surpasses the predicted ARIMA price, and sell signals when it falls below the predicted level.\n",
      "   - **Trading Rule**: Enter position when momentum indicators (like moving averages) signal an upward trend; exit position if the price reverses.\n",
      "\n",
      "2. **Volatility Breakout Strategy**:\n",
      "   - **Use Case**: This strategy exploits periods of high volatility determined through GARCH models.\n",
      "   - **Indicators**: \n",
      "     - Analyze GARCH model outputs for predicted volatility. \n",
      "     - Execute buy orders when NVDA’s price penetrates upper volatility bounds, and sell orders when it breaches lower volatility limits.\n",
      "   - **Trading Rule**: Enter position on breakout events; cut losses when the price closes back within the volatility bands established.\n",
      "\n",
      "3. **Statistical Arbitrage Strategy**:\n",
      "   - **Use Case**: Ideal for capturing short-lived price discrepancies through statistical techniques.\n",
      "   - **Indicators**:\n",
      "     - Continuously monitor price correlations and use ARIMA to predict mean-reversion of NVDA prices.\n",
      "     - Establish a hedge by taking opposite positions in correlated assets (e.g., tech sector ETFs).\n",
      "   - **Trading Rule**: Buy NVDA when price drops significantly compared to historical averages; sell once it returns to the predicted mean.\n",
      "\n",
      "4. **Risk Managed Positioning**:\n",
      "   - **Use Case**: Aimed at creating a flexible portfolio that adjusts based on GARCH-derived risk assessments.\n",
      "   - **Indicators**:\n",
      "     - Periodically review GARCH models to adjust the position size based on the predicted volatility – larger positions in low volatility periods and smaller in high volatility periods.\n",
      "   - **Trading Rule**: Enter with a position size effectively moderated by anticipated risk levels to manage exposure while maximizing profit potential.\n",
      "\n",
      "5. **Event-Based Trading Strategy**:\n",
      "   - **Use Case**: Focus on taking advantage of corporate events (earnings reports, product launches).\n",
      "   - **Indicators**:\n",
      "     - Utilize historical data and ARIMA forecasts to anticipate stock price movements surrounding significant corporate announcements.\n",
      "     - Prepare for potential volatility spikes as observed through GARCH forecasts.\n",
      "   - **Trading Rule**: Buy NVDA shares in anticipation of positive earnings surprises, and consider protective stops to mitigate downside risks following the announcements.\n",
      "\n",
      "Each of these strategies utilizes the insights derived from ARIMA and GARCH models to craft approaches tailored to a medium-risk tolerance level, specifically accommodating day trading preferences. The combination of predictive modeling and risk assessment ensures the strategies are well-rounded, aiming for both profit realization and loss limitation.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### this execution will take some time to run\n",
    "result = financial_trading_crew.kickoff(inputs=financial_trading_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Potential Trading Strategies for NVDA Aligned with Medium Risk Tolerance:**\n",
       "\n",
       "1. **Momentum Trading Strategy**:\n",
       "   - **Use Case**: Designed for short-term trading (day trading) based on the momentum of stock price movements.\n",
       "   - **Indicators**: \n",
       "     - Utilize ARIMA for time series forecasting to identify upward momentum in NVDA stock prices.\n",
       "     - Implementation of buy signals when the price surpasses the predicted ARIMA price, and sell signals when it falls below the predicted level.\n",
       "   - **Trading Rule**: Enter position when momentum indicators (like moving averages) signal an upward trend; exit position if the price reverses.\n",
       "\n",
       "2. **Volatility Breakout Strategy**:\n",
       "   - **Use Case**: This strategy exploits periods of high volatility determined through GARCH models.\n",
       "   - **Indicators**: \n",
       "     - Analyze GARCH model outputs for predicted volatility. \n",
       "     - Execute buy orders when NVDA’s price penetrates upper volatility bounds, and sell orders when it breaches lower volatility limits.\n",
       "   - **Trading Rule**: Enter position on breakout events; cut losses when the price closes back within the volatility bands established.\n",
       "\n",
       "3. **Statistical Arbitrage Strategy**:\n",
       "   - **Use Case**: Ideal for capturing short-lived price discrepancies through statistical techniques.\n",
       "   - **Indicators**:\n",
       "     - Continuously monitor price correlations and use ARIMA to predict mean-reversion of NVDA prices.\n",
       "     - Establish a hedge by taking opposite positions in correlated assets (e.g., tech sector ETFs).\n",
       "   - **Trading Rule**: Buy NVDA when price drops significantly compared to historical averages; sell once it returns to the predicted mean.\n",
       "\n",
       "4. **Risk Managed Positioning**:\n",
       "   - **Use Case**: Aimed at creating a flexible portfolio that adjusts based on GARCH-derived risk assessments.\n",
       "   - **Indicators**:\n",
       "     - Periodically review GARCH models to adjust the position size based on the predicted volatility – larger positions in low volatility periods and smaller in high volatility periods.\n",
       "   - **Trading Rule**: Enter with a position size effectively moderated by anticipated risk levels to manage exposure while maximizing profit potential.\n",
       "\n",
       "5. **Event-Based Trading Strategy**:\n",
       "   - **Use Case**: Focus on taking advantage of corporate events (earnings reports, product launches).\n",
       "   - **Indicators**:\n",
       "     - Utilize historical data and ARIMA forecasts to anticipate stock price movements surrounding significant corporate announcements.\n",
       "     - Prepare for potential volatility spikes as observed through GARCH forecasts.\n",
       "   - **Trading Rule**: Buy NVDA shares in anticipation of positive earnings surprises, and consider protective stops to mitigate downside risks following the announcements.\n",
       "\n",
       "Each of these strategies utilizes the insights derived from ARIMA and GARCH models to craft approaches tailored to a medium-risk tolerance level, specifically accommodating day trading preferences. The combination of predictive modeling and risk assessment ensures the strategies are well-rounded, aiming for both profit realization and loss limitation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "Markdown(result.raw)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
